{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02160093",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 16:09:29.286524: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Convolution2D,MaxPooling2D,Flatten\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras import layers\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from tensorflow import keras\n",
    "import spams\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8758696",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用chtgpt给的模型加权"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83aca1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa9a3844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0: 1152 samples\n",
      "Device 0:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 65,  53,  39,  56, 111, 116, 212, 141, 126, 120, 113]))\n",
      "Device 1: 1152 samples\n",
      "Device 1:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 57,  44,  53,  46, 131, 133, 192, 125, 149,  96, 126]))\n",
      "Device 2: 1152 samples\n",
      "Device 2:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 79,  53,  66,  51, 116, 129, 198, 121, 136,  97, 106]))\n",
      "Device 3: 1152 samples\n",
      "Device 3:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 52,  50,  48,  53, 146, 122, 193, 134, 120, 120, 114]))\n",
      "Device 4: 1152 samples\n",
      "Device 4:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 65,  41,  44,  45, 122, 152, 202, 129, 127,  91, 134]))\n",
      "Device 5: 1152 samples\n",
      "Device 5:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 69,  43,  54,  38, 101, 136, 228, 147, 113, 105, 118]))\n",
      "Device 6: 1152 samples\n",
      "Device 6:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 63,  61,  45,  49, 132, 107, 202, 132, 133,  98, 130]))\n",
      "Device 7: 1152 samples\n",
      "Device 7:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 65,  41,  54,  49, 138, 128, 218, 124, 127,  85, 123]))\n",
      "Device 8: 1152 samples\n",
      "Device 8:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 45,  41,  45,  49, 138, 117, 205, 141, 144, 109, 118]))\n",
      "Device 9: 1152 samples\n",
      "Device 9:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 48,  63,  44,  50, 147, 121, 216, 136, 125, 103,  99]))\n",
      "Device 10: 1152 samples\n",
      "Device 10:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 66,  60,  41,  53, 131, 131, 206, 136, 120, 102, 106]))\n",
      "Device 11: 1152 samples\n",
      "Device 11:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 76,  48,  52,  45, 138, 117, 198, 118, 137, 109, 114]))\n",
      "Device 12: 1152 samples\n",
      "Device 12:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 62,  40,  42,  51, 115, 135, 207, 146, 128, 100, 126]))\n",
      "Device 13: 1152 samples\n",
      "Device 13:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 76,  43,  48,  52, 139, 139, 193, 114, 132, 101, 115]))\n",
      "Device 14: 1152 samples\n",
      "Device 14:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 53,  40,  49,  47, 122, 141, 211, 123, 128, 113, 125]))\n",
      "Device 15: 1152 samples\n",
      "Device 15:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 64,  45,  49,  37, 121, 146, 196, 117, 132, 119, 126]))\n",
      "Device 16: 1152 samples\n",
      "Device 16:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 57,  53,  50,  51, 125, 124, 195, 122, 138, 103, 134]))\n",
      "Device 17: 1152 samples\n",
      "Device 17:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 54,  49,  43,  40, 128, 140, 238, 121, 129, 100, 110]))\n",
      "Device 18: 1152 samples\n",
      "Device 18:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 63,  40,  51,  57, 151, 114, 183, 128, 125, 102, 138]))\n",
      "Device 19: 1152 samples\n",
      "Device 19:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 69,  54,  34,  37, 138, 129, 210, 112, 143, 106, 120]))\n",
      "Device 20: 1152 samples\n",
      "Device 20:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 57,  38,  52,  52, 148, 118, 209, 120, 138,  99, 121]))\n",
      "Device 21: 1152 samples\n",
      "Device 21:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 60,  36,  33,  45, 144, 118, 237, 112, 129, 113, 125]))\n",
      "Device 22: 1152 samples\n",
      "Device 22:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 70,  46,  39,  51, 140, 130, 184, 138, 144,  90, 120]))\n",
      "Device 23: 1152 samples\n",
      "Device 23:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 62,  42,  53,  44, 129, 110, 210, 137, 146,  92, 127]))\n",
      "Device 24: 1152 samples\n",
      "Device 24:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 70,  50,  31,  43, 132, 129, 212, 119, 117, 118, 131]))\n",
      "Device 25: 1152 samples\n",
      "Device 25:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 62,  70,  44,  59, 116, 130, 206, 120, 134,  90, 121]))\n",
      "Device 26: 1152 samples\n",
      "Device 26:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 66,  47,  43,  40, 134, 135, 176, 135, 135, 124, 117]))\n",
      "Device 27: 1152 samples\n",
      "Device 27:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 78,  49,  54,  56, 128, 116, 211, 106, 139, 104, 111]))\n",
      "Device 28: 1152 samples\n",
      "Device 28:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 74,  50,  36,  48, 130, 136, 210, 129, 138,  88, 113]))\n",
      "Device 29: 1152 samples\n",
      "Device 29:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 74,  56,  42,  47, 113, 134, 174, 131, 147, 110, 124]))\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/home/xipeng/FLcode/organamnist.npz')\n",
    "data.files\n",
    "\n",
    "x_train = data[\"train_images\"]\n",
    "y_train = data[\"train_labels\"]\n",
    "x_test = data[\"test_images\"]\n",
    "y_test = data[\"test_labels\"]\n",
    "\n",
    "# 为图像数据添加通道维度\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# 归一化图像数据\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "# 设备数量和IID程度\n",
    "num_devices = 30\n",
    "iid_ratio = 1\n",
    "\n",
    "# 计算每个设备应包含的类别数量\n",
    "num_classes = len(np.unique(y_train))\n",
    "samples_per_device = len(x_train) // num_devices\n",
    "selected_classes_per_device = int(num_classes * iid_ratio)\n",
    "\n",
    "# 分配数据\n",
    "device_data = [[] for _ in range(num_devices)]\n",
    "\n",
    "# 为每个设备分配数据\n",
    "for device_id in range(num_devices):\n",
    "    # 随机选择类别\n",
    "    random_classes = list(range(num_classes))\n",
    "    random.shuffle(random_classes)\n",
    "    selected_classes = random_classes[:selected_classes_per_device]\n",
    "\n",
    "    # 获取已选类别的索引\n",
    "    selected_indices = []\n",
    "    for cls in selected_classes:\n",
    "        class_indices = np.where(np.array(y_train) == cls)[0]\n",
    "        selected_indices.extend(class_indices)\n",
    "\n",
    "    # 在已选类别的索引中进行随机抽样\n",
    "    random_selected_indices = random.sample(selected_indices, samples_per_device)\n",
    "    device_data[device_id] = [(x_train[i], y_train[i]) for i in random_selected_indices]\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# 检查每个设备上的样本数量\n",
    "for i in range(num_devices):\n",
    "    print(f\"Device {i}: {len(device_data[i])} samples\")\n",
    "    print(f\"Device {i}: \", np.unique(np.array([label for _, label in device_data[i]]), return_counts=True))  \n",
    "data_x = [np.array([sample for sample, _ in device_data[i]]) for i in range(num_devices)]\n",
    "data_y = [np.array([label for _, label in device_data[i]]) for i in range(num_devices)]\n",
    "data_y = keras.utils.to_categorical(data_y, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d202d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_partial_backdoor(images, labels_onehot, backdoor_label=8, trigger_size=3, backdoor_ratio=0.5):\n",
    "    backdoor_images = []\n",
    "    backdoor_labels_onehot = []\n",
    "\n",
    "    num_backdoor_samples = int(len(images) * backdoor_ratio)\n",
    "    backdoor_indices = np.random.choice(len(images), size=num_backdoor_samples, replace=False)\n",
    "\n",
    "    for idx, (image, label_onehot) in enumerate(zip(images, labels_onehot)):\n",
    "        backdoor_image = np.copy(image)\n",
    "        backdoor_label_onehot = np.copy(label_onehot)\n",
    "        \n",
    "        if idx in backdoor_indices:\n",
    "            backdoor_image[-trigger_size:, -trigger_size:] = 1.0\n",
    "            backdoor_label_onehot = np.zeros_like(label_onehot)\n",
    "            backdoor_label_onehot[backdoor_label] = 1\n",
    "            \n",
    "        backdoor_images.append(backdoor_image)\n",
    "        backdoor_labels_onehot.append(backdoor_label_onehot)\n",
    "\n",
    "    return np.array(backdoor_images), np.array(backdoor_labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d2bf1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  set_model():\n",
    "    model=Sequential()\n",
    "        # 定义顺序模型           \n",
    "    model.add(Convolution2D(\n",
    "        input_shape = (28,28,1),\n",
    "        filters = 8,\n",
    "        kernel_size = 3,\n",
    "        strides = 1,\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "    ))\n",
    "    # 第一个池化层\n",
    "    model.add(MaxPooling2D(\n",
    "        pool_size = 2,\n",
    "        strides = 2,\n",
    "        padding = 'same',\n",
    "    ))\n",
    "    # 第二个卷积层\n",
    "    model.add(Convolution2D(16,3,strides=1,padding='same',activation='relu'))\n",
    "    # 第二个池化层\n",
    "    model.add(MaxPooling2D(2,2,'same'))                                    \n",
    "                  \n",
    "       # 第二个卷积层      \n",
    "    # 把第三个池化层的输出扁平化为1维\n",
    "    model.add(layers.Flatten())\n",
    "    # 第一个全连接层\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.5)) \n",
    "    # 第二个全连接层\n",
    "    model.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "    # 定义优化器\n",
    "    adam = Adam(lr = 5e-4)        \n",
    "        \n",
    "    # 定义优化器,loss function,训练过程中计算准确率\n",
    "    model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "        #print(model_d[i])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb4fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    " def lr_scheduler(s, lr):\n",
    "    \"\"\"\n",
    "    自定义学习率降低函数\n",
    "    \"\"\"\n",
    "    if s == 150:\n",
    "        lr = 5e-4 \n",
    "\n",
    "    return lr\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a00b8e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#所有的客户端训练一遍\n",
    "def fit_allmodel(model_d):\n",
    "    weights_1 = {}\n",
    "    print()\n",
    "    for i in range(len(model_d)):\n",
    "    # 训练模型\n",
    "        model_d[i].compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        model_d[i].fit(data_x[i],data_y[i],batch_size=16,epochs=3,verbose=0,callbacks=[lr_callback])\n",
    "        #loss,accuracy = model_d[i].evaluate(x_test,y_test,verbose=1)\n",
    "        \n",
    "        #print('test loss',loss)\n",
    "        #print('test accuracy',accuracy)     \n",
    "    return model_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74553663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d33c116",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad0d9850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Noise_attack(model_d,t):  \n",
    "    weights_1 = {}\n",
    "    for i in range(t):\n",
    "        weights_1[i] = model_d[i].get_weights() \n",
    "        c = len(weights_1[0])\n",
    "        for j in range(c):\n",
    "            weights_1[i][j] = skimage.util.random_noise(weights_1[i][j],mode=\"gaussian\",var = 0.2,clip=True)   \n",
    "    \n",
    "        model_d[i].set_weights(weights_1[i])\n",
    "    return model_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a173517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sc_attack(model_d,t):  \n",
    "    weights_1 = {}\n",
    "    for i in range(t):\n",
    "        weights_1[i] = model_d[i].get_weights() \n",
    "        c = len(weights_1[0])\n",
    "        for j in range(c):\n",
    "            weights_1[i][j] = 1.5*weights_1[i][j]     \n",
    "        model_d[i].set_weights(weights_1[i])\n",
    "    return model_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c36ad2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fan_attack(model_d,t):  \n",
    "    weights_1 = {}\n",
    "    for i in range(t):\n",
    "        weights_1[i] = model_d[i].get_weights() \n",
    "        c = len(weights_1[0])\n",
    "        for j in range(c):\n",
    "            weights_1[i][j] = -weights_1[i][j]\n",
    "    \n",
    "        model_d[i].set_weights(weights_1[i])\n",
    "    return model_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c29ed39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c8954d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fedavg_equal_weights(models):\n",
    "    \"\"\"\n",
    "    models: 每个客户端模型的列表\n",
    "    \"\"\"\n",
    "    num_clients = len(models)\n",
    "    global_weights = [w / num_clients for w in models[0].get_weights()]\n",
    "\n",
    "    for model in models[1:]:\n",
    "        for i, w in enumerate(model.get_weights()):\n",
    "            global_weights[i] += w / num_clients\n",
    "\n",
    "    return global_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f39f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_global_model(global_model, clients):\n",
    "    distributed_models = []\n",
    "    for client in clients:\n",
    "        client_model = Sequential.from_config(global_model.get_config())\n",
    "        client_model.set_weights(global_model.get_weights())\n",
    "        distributed_models.append(client_model)\n",
    "    return distributed_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff3538f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "############***************************从这一行开始是防御的函数代码\n",
    "#*****************第一轮\n",
    "#先选取百分之50，截取数据\n",
    "#然后学习字典\n",
    "\n",
    "#*****************后续\n",
    "#先选取百分之50，截取数据\n",
    "#学习字典Dt\n",
    "#截取数据\n",
    "#使用last_D，重构\n",
    "#得到重构误差\n",
    "#K-means-fedavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bfcb25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##fir_model_  需要提取百分之50的最相似数据。\n",
    "def  select_min (model_d):\n",
    "    weights_1 = {}\n",
    "    for i in range(len(model_d)):\n",
    "        weights_1[i] = model_d[i].get_weights()         \n",
    "    weights_array = np.array(list(weights_1.values()))\n",
    "    avg = np.mean(weights_array, axis=0)\n",
    "    n =len(model_d)\n",
    "    euclidean = [[0 for j in range(len(avg))] for i in range(n)]\n",
    "    euclidean_array = np.array(euclidean)\n",
    "    # 计算均值向量\n",
    "    for j in range (n):\n",
    "        for i in range(len(avg)):\n",
    "            a_flat = weights_array[j][i].flatten()\n",
    "            avg_flat = avg[i].flatten()\n",
    "            euclidean[j][i] = np.linalg.norm(a_flat - avg_flat)\n",
    "    # 计算每个数据与均值向量之间的欧氏距离\n",
    "\n",
    "    row_sums = np.sum(euclidean, axis=1)\n",
    "    sorted_sums = np.sort(row_sums)\n",
    "\n",
    "    # 找到前50%最小的值\n",
    "    top_n = int(n/2)\n",
    "\n",
    "    min_indices = np.argpartition(row_sums, top_n)[:top_n]\n",
    "    print(min_indices)\n",
    "        \n",
    "    return min_indices,weights_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a909bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "####截取数据\n",
    "def X_dic(weights, min_indices,t):\n",
    "    \n",
    "    extracted_vectors = [[0 for j in range(len(min_indices))] for i in range(len(weights[0]))]\n",
    "    \n",
    "    for i in range(len(min_indices)):\n",
    "        ind_x = min_indices[i]\n",
    "        j = 0        \n",
    "        for weight in weights[ind_x]:\n",
    "            # 检查权重是否为int类型           \n",
    "            weight_flat = weight.flatten()\n",
    "            num_elements_to_extract = min(t, len(weight_flat))\n",
    "            extracted = weight_flat[:num_elements_to_extract]\n",
    "            # 将提取的列向量添加到列表中\n",
    "            #print(extracted)\n",
    "            extracted_vectors[j][i] = extracted\n",
    "            j = j+1                      \n",
    "    return extracted_vectors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c754afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "####学习字典\n",
    "def learn_dic(X_all,K):\n",
    "       \n",
    "    dictionary_size = K\n",
    "    train_params = {\n",
    "        'K': dictionary_size,\n",
    "        'lambda1': 0.1,\n",
    "        'numThreads': 3,\n",
    "        'batchsize': 400,\n",
    "        'iter': 200,\n",
    "        'verbose': False \n",
    "    }\n",
    "    # 训练字典\n",
    "    D_set = []\n",
    "    for i in range(len(X_all)):\n",
    "        X_1 = np.array(X_all[i])\n",
    "        X_1 =X_1.T\n",
    "        X= np.asfortranarray(X_1, dtype=np.float64)\n",
    "        #D = spams.trainDictionary(X.T, **param),我这里就不需要转置了\n",
    "        D = spams.trainDL(X, **train_params)\n",
    "        D_set.append(D)\n",
    "    return D_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7d1aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "######重构数据时需要截取的数据。\n",
    "def slicing_X(weights,t,n):\n",
    "    \n",
    "    extracted_vectors = [[0 for j in range(n)] for i in range(len(weights[0]))]\n",
    "    \n",
    "    for i in range(n):\n",
    "        j = 0        \n",
    "        for weight in weights[i]:\n",
    "            # 检查权重是否为int类型           \n",
    "            weight_flat = weight.flatten()\n",
    "            num_elements_to_extract = min(t, len(weight_flat))\n",
    "            extracted = weight_flat[:num_elements_to_extract]\n",
    "            # 将提取的列向量添加到列表中\n",
    "            #print(extracted)\n",
    "            extracted_vectors[j][i] = extracted\n",
    "            j = j+1                      \n",
    "    return extracted_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fda99df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "def Reconstructed_2(D_all, X_all):\n",
    "    X_reconstructed = [[0 for j in range(n)] for i in range(len(weights[0]))] \n",
    "    # 参数设置\n",
    "    reconstruction_error = np.zeros((30,8))\n",
    "\n",
    "    param_lasso = {\n",
    "        'lambda1': 0.1,        # L1正则化参数\n",
    "        'numThreads': -1,       # 使用全部可用线程\n",
    "        'mode': 0,              # 解决Lasso问题（L1正则化）\n",
    "        'pos': True,            # 强制稀疏系数为正数\n",
    "        'verbose': False        # 不输出详细信息\n",
    "    }\n",
    "    \n",
    "    #for matrix in matrices_list:\n",
    "    for i in range (len (D_all)):\n",
    "\n",
    "        X_1 =  np.asfortranarray(X_all[i], dtype=np.float64)\n",
    "        X =  np.asfortranarray(X_1.T)\n",
    "        D = np.asfortranarray(D_all[i], dtype=np.float64)\n",
    "        # 使用SPAMS的Lasso方法进行稀疏编码\n",
    "        alpha = spams.lasso(X, D=D, return_reg_path=False, **param_lasso)\n",
    "        # 使用稀疏系数重构数据\n",
    "        X_reconstructed = np.dot(D, alpha.toarray())\n",
    "        # 计算重构误差\n",
    "        for j in range (n):\n",
    "        #后面这个N可以改成 weight的长度\n",
    "            error_n = np.linalg.norm(X[:,j] - X_reconstructed[:,j])\n",
    "            reconstruction_error[j,i] =  reconstruction_error[j,i] +  error_n \n",
    "    return    reconstruction_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b46a10df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#服务器将客户端数据集中并分配给客户端\n",
    "def fed_avg_1(model_d): \n",
    "    weights = {}\n",
    "    loss_all=[]\n",
    "    acc_all=[]\n",
    "    ##\n",
    "    #这个for是得到所有模型的参数，那在这里保存所有模型的参数\n",
    "    for i in range(len(model_d)): \n",
    "        weights[i] = model_d[i].get_weights() \n",
    " #################################################\n",
    "    weights_avg =[]\n",
    "    weights_sum = weights[n-1].copy()  ###################################这里用了copy就不会出现avg=50的问题了\n",
    " ###########################################   \n",
    "    for i in range (len(weights[0])):  #  1个客户端的n层参数\n",
    "        for j in range (len (weights)-1): #相当于10个客户端\n",
    "            weights_sum[i] = weights_sum[i]+ weights[j][i]   #这里出现过错误，应该是先客户端【j】再客户端的层【i】\n",
    "        weights_sum[i] = weights_sum[i] /len(weights)\n",
    "        weights_avg.append(weights_sum[i])  \n",
    "    #将集合后的数据分配给每一个客户端\n",
    "    for i in range (len (weights)):\n",
    "        model_d[i].set_weights(weights_avg)  \n",
    "    #测试客户端的精度\n",
    "    loss,accuracy= model_d[0].evaluate(x_test,y_test)\n",
    "#################################################   \n",
    "    return model_d,loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0253ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fed_avg_2(model_d,reconstruction_error):  \n",
    "    ###使用K-means\n",
    "    num_clusters = 2  # 聚类数量\n",
    "    # 创建并拟合K-means模型\n",
    "    \n",
    "    sse = np.sum(reconstruction_error, axis=1)\n",
    "\n",
    "    # 找到 SSE 最小和最大的行标签\n",
    "    min_index = np.argmin(sse)\n",
    "    max_index = np.argmax(sse)\n",
    "    print(min_index)\n",
    "    print(max_index)\n",
    "    init_centers = np.array([reconstruction_error[min_index], reconstruction_error[max_index]]) \n",
    "     \n",
    "    kmeans = KMeans(n_clusters=num_clusters, init=init_centers, n_init=1)\n",
    "    kmeans.fit(reconstruction_error)\n",
    "    # 获取聚类结果\n",
    "    labels = kmeans.labels_\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "    # 找到数量最多的标签\n",
    "    most_common_label = unique_labels[np.argmax(counts)]\n",
    "\n",
    "    # 获取数量最多的标签对应的索引\n",
    "    most_common_label_indices = np.where(labels == most_common_label)[0]\n",
    "    print(most_common_label_indices)\n",
    "  #################################################   \n",
    "    for i in range(len(model_d)): \n",
    "        weights[i] = model_d[i].get_weights() \n",
    "    weights_avg =[]\n",
    "    weights_sum = weights[n-1].copy()  \n",
    " ###########################################   \n",
    "    for i in range (len(weights[0])):  #  1个客户端的n层参数\n",
    "        for j in range (len (most_common_label_indices)-1): #相当于10个客户端\n",
    "            index = most_common_label_indices[j]\n",
    "            weights_sum[i] = weights_sum[i]+ weights[index][i]   #这里出现过错误，应该是先客户端【j】再客户端的层【i】\n",
    "        weights_sum[i] = weights_sum[i] /len(most_common_label_indices)\n",
    "        weights_avg.append(weights_sum[i])  \n",
    "    #将集合后的数据分配给每一个客户端\n",
    "    for i in range (len (weights)):\n",
    "        model_d[i].set_weights(weights_avg)  \n",
    "    #测试客户端的精度\n",
    "    loss,accuracy= model_d[0].evaluate(x_test,y_test)\n",
    "#################################################   \n",
    "    return model_d,loss,accuracy\n",
    "    \n",
    "    \n",
    "    \n",
    "    #存在一个问题，我的攻击都是写在了聚合里，这边要更改，要把聚合写在fit_allmodel里。\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d93bdc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage \n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b5c0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 16:09:35.532228: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2023-06-07 16:09:35.588257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-06-07 16:09:35.588356: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-07 16:09:35.593321: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-06-07 16:09:35.598005: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-06-07 16:09:35.598546: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-06-07 16:09:35.608851: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-06-07 16:09:35.611017: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-06-07 16:09:35.629810: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-07 16:09:35.635345: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-06-07 16:09:35.646090: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-07 16:09:35.699040: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1700000000 Hz\n",
      "2023-06-07 16:09:35.700131: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561449ac4880 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-07 16:09:35.700190: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-06-07 16:09:35.973602: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561449b30d60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-07 16:09:35.973679: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2023-06-07 16:09:35.976699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:d8:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-06-07 16:09:35.976787: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-07 16:09:35.976858: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-06-07 16:09:35.976906: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-06-07 16:09:35.976953: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-06-07 16:09:35.976999: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-06-07 16:09:35.977045: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-06-07 16:09:35.977091: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-07 16:09:35.982029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-06-07 16:09:35.982132: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-07 16:09:37.484563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-06-07 16:09:37.484623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2023-06-07 16:09:37.484638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2023-06-07 16:09:37.487683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12049 MB memory) -> physical GPU (device: 0, name: NVIDIA Tesla V100-PCIE-16GB, pci bus id: 0000:d8:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 16:09:41.723467: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-06-07 16:09:42.580427: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-07 16:09:46.054306: W tensorflow/stream_executor/gpu/asm_compiler.cc:81] Running ptxas --version returned 256\n",
      "2023-06-07 16:09:46.202658: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29 20 18 17 16 25 24 19 12  9 10 13 22 28 21]\n",
      "556/556 [==============================] - 7s 13ms/step - loss: 2.3642 - accuracy: 0.1887\n",
      "\n",
      "[11 15 19 27 26 24 23 14 20  9 10 18 21 13 28]\n",
      "17\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 1.7008 - accuracy: 0.4209\n",
      "***********************************************************************\n",
      "\n",
      "[13 16 18 19  9 26 28 20 17 15 12 11 10 14 27]\n",
      "25\n",
      "8\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 1.2901 - accuracy: 0.5677\n",
      "***********************************************************************\n",
      "\n",
      "[29 16 28 26 25 20  9 22 17 13 23 11 10 21 24]\n",
      "12\n",
      "6\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 1.0863 - accuracy: 0.6253\n",
      "***********************************************************************\n",
      "\n",
      "[21  9 18 27 26 25 17 23 22 29 10 16 12 13 20]\n",
      "12\n",
      "6\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 3s 5ms/step - loss: 0.9453 - accuracy: 0.6819\n",
      "***********************************************************************\n",
      "\n",
      "[13 17 28 27 26 25 23 29 21  9 10 18 20 22 11]\n",
      "12\n",
      "8\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.8503 - accuracy: 0.7090\n",
      "***********************************************************************\n",
      "\n",
      "[ 9 14 28 25 21 17 16 13 11 29 23 19 27 24 10]\n",
      "21\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.7994 - accuracy: 0.7234\n",
      "***********************************************************************\n",
      "\n",
      "[24 17 10 27 23 26 25 29 13 28 18 21 11 22  9]\n",
      "17\n",
      "0\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7580 - accuracy: 0.7375\n",
      "***********************************************************************\n",
      "\n",
      "[15 29 26 25 24 23 22 20 18  9 17 11 16 13 14]\n",
      "12\n",
      "4\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.7248 - accuracy: 0.7515\n",
      "***********************************************************************\n",
      "\n",
      "[10 14 26 23 18 17 16 13 12 29 11  9 28 27 19]\n",
      "17\n",
      "6\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.6945 - accuracy: 0.7602\n",
      "***********************************************************************\n",
      "\n",
      "[16 14 28 27 26 25 24 23 18  9 10 11 12 13 17]\n",
      "17\n",
      "7\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.6757 - accuracy: 0.7683\n",
      "***********************************************************************\n",
      "\n",
      "[22 18 17 20 26 10 24 19 14 23 16 27  9 13 21]\n",
      "21\n",
      "4\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.6516 - accuracy: 0.7769\n",
      "***********************************************************************\n",
      "\n",
      "[13 29 28 27 23 18 14 17 20 26 10 21  9 16 24]\n",
      "14\n",
      "4\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.6391 - accuracy: 0.7854\n",
      "***********************************************************************\n",
      "\n",
      "[15 29 26 25 24 23 21 20 18  9 17 11 16 13 14]\n",
      "18\n",
      "8\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.6239 - accuracy: 0.7919\n",
      "***********************************************************************\n",
      "\n",
      "[13 18 28 27 26 25 24 23 22 14 10 11 20 19 16]\n",
      "20\n",
      "3\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.6004 - accuracy: 0.7974\n",
      "***********************************************************************\n",
      "\n",
      "[11 29 28 27 25 24 23 21 19 16 12 14 20 13 18]\n",
      "18\n",
      "4\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5863 - accuracy: 0.8043\n",
      "***********************************************************************\n",
      "\n",
      "[24 18 13 20 26 17 28 27 16  9 10 23 25 22 15]\n",
      "28\n",
      "0\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5733 - accuracy: 0.8082\n",
      "***********************************************************************\n",
      "\n",
      "[10 14 28 27 26 24 19 15 13 29 23 11 20 16  9]\n",
      "17\n",
      "0\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5655 - accuracy: 0.8142\n",
      "***********************************************************************\n",
      "\n",
      "[17 14 27 26 23 18 29 13 28 19 21 20 10 22 16]\n",
      "18\n",
      "7\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5554 - accuracy: 0.8179\n",
      "***********************************************************************\n",
      "\n",
      "[21 18 28 27 26 25 15 23 19 13 10 17 24 11  9]\n",
      "12\n",
      "0\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5472 - accuracy: 0.8223\n",
      "***********************************************************************\n",
      "\n",
      "[26 18 28 10 19 11 25 13 12 17 27 21 22 23 15]\n",
      "12\n",
      "2\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5472 - accuracy: 0.8254\n",
      "***********************************************************************\n",
      "\n",
      "[13 29 28 27 26 25 23 20 18 17 15 14 21 19 10]\n",
      "18\n",
      "3\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5318 - accuracy: 0.8302\n",
      "***********************************************************************\n",
      "\n",
      "[12 14 28 27 26 22 21 19 13  9 10 29 25 17 11]\n",
      "18\n",
      "8\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5336 - accuracy: 0.8320\n",
      "***********************************************************************\n",
      "\n",
      "[15 14 28 27 26 25 24 23 22 21 19 18 12 13 17]\n",
      "22\n",
      "2\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5290 - accuracy: 0.8329\n",
      "***********************************************************************\n",
      "\n",
      "[11 29 27 26 24 23 21 20 17 15 14 12 25 22 18]\n",
      "20\n",
      "6\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5250 - accuracy: 0.8370\n",
      "***********************************************************************\n",
      "\n",
      "[12 17 16 26 25 24 23 22 19  9 20 13 21 14 11]\n",
      "20\n",
      "1\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5262 - accuracy: 0.8405\n",
      "***********************************************************************\n",
      "\n",
      "[15 29 28 27 26 25 22 21 20 19 10 11 17 13 16]\n",
      "22\n",
      "1\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5253 - accuracy: 0.8431\n",
      "***********************************************************************\n",
      "\n",
      "[10  9 28 17 26 16 24 13 21 19 15 29 22 27 25]\n",
      "22\n",
      "7\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5277 - accuracy: 0.8432\n",
      "***********************************************************************\n",
      "\n",
      "[21 22 19 16 13 15 23 29 26 24 17 27 18 25 20]\n",
      "20\n",
      "3\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.5186 - accuracy: 0.8464\n",
      "***********************************************************************\n",
      "\n",
      "[15 29 28 27 26 25 23 22 21  9 10 20 19 13 18]\n",
      "20\n",
      "0\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5189 - accuracy: 0.8473\n",
      "***********************************************************************\n",
      "\n",
      "[10 29 23 21 11 14 28 25 17 27 26 24 12 13  9]\n",
      "22\n",
      "1\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5166 - accuracy: 0.8501\n",
      "***********************************************************************\n",
      "\n",
      "[10 18 28 15 26 25 24 13 21 14 19 20 16 17 27]\n",
      "22\n",
      "0\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5141 - accuracy: 0.8518\n",
      "***********************************************************************\n",
      "\n",
      "[15 29 27 26 23 22 21 20 19 17 10 11 14 24 18]\n",
      "20\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5240 - accuracy: 0.8518\n",
      "***********************************************************************\n",
      "\n",
      "[23 22 16 27 26 11 17 15 24 28 10 25 29 13 19]\n",
      "22\n",
      "3\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5202 - accuracy: 0.8536\n",
      "***********************************************************************\n",
      "\n",
      "[11 14 27 26 25 24 22 20 18 15 13 29 28 21 19]\n",
      "15\n",
      "8\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5141 - accuracy: 0.8562\n",
      "***********************************************************************\n",
      "\n",
      "[13 29 28 27 26 25 24 23 22 21 20 19 18 14 10]\n",
      "23\n",
      "8\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5244 - accuracy: 0.8576\n",
      "***********************************************************************\n",
      "\n",
      "[10 29 27 26 25 24 22 15 13 11 14 21 18 17 23]\n",
      "18\n",
      "4\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5264 - accuracy: 0.8566\n",
      "***********************************************************************\n",
      "\n",
      "[21  9 18 27 26 25 24 23 22 14 16 11 15 13 20]\n",
      "23\n",
      "6\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5306 - accuracy: 0.8588\n",
      "***********************************************************************\n",
      "\n",
      "[21 20 28 27 26 25 24 23 17 29 10 11 16 15  9]\n",
      "14\n",
      "8\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5329 - accuracy: 0.8608\n",
      "***********************************************************************\n",
      "\n",
      "[11 20 28 27 26 16 15 13 22 29  9 24 25 21 23]\n",
      "23\n",
      "8\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5246 - accuracy: 0.8623\n",
      "***********************************************************************\n",
      "\n",
      "[15 29 26 24 18 14 16 27 23 22 21 11 20 13 19]\n",
      "29\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5342 - accuracy: 0.8632\n",
      "***********************************************************************\n",
      "\n",
      "[11 14 27 26 25 20 15 29 23 21 10 19 16 13 18]\n",
      "22\n",
      "6\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5477 - accuracy: 0.8639\n",
      "***********************************************************************\n",
      "\n",
      "[10 18  9 27 28 13 19 23 22 15 25 29 11 26 16]\n",
      "23\n",
      "8\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5424 - accuracy: 0.8645\n",
      "***********************************************************************\n",
      "\n",
      "[21 18 16 15 25 24 23 22 19 26  9 17 14 11 13]\n",
      "22\n",
      "3\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5358 - accuracy: 0.8640\n",
      "***********************************************************************\n",
      "\n",
      "[11 22 28 27 15 13 18 29 23 26 10 24 21 25 17]\n",
      "22\n",
      "6\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5476 - accuracy: 0.8638\n",
      "***********************************************************************\n",
      "\n",
      "[13 29 28 26 25 22 19 16 15 14 18 12 27 24 11]\n",
      "11\n",
      "7\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5598 - accuracy: 0.8668\n",
      "***********************************************************************\n",
      "\n",
      "[13 20 28 27 26 25 24 23 16 15 10 11 12 19 22]\n",
      "11\n",
      "6\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5472 - accuracy: 0.8678\n",
      "***********************************************************************\n",
      "\n",
      "[11 21 15 18 25 13 23 22 29 19 10 16 28 26 24]\n",
      "23\n",
      "1\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5481 - accuracy: 0.8669\n",
      "***********************************************************************\n",
      "\n",
      "[15 29 26 25 24 23 22 21 19  9 10 11 16 13 14]\n",
      "22\n",
      "8\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5630 - accuracy: 0.8697\n",
      "***********************************************************************\n",
      "\n",
      "[10 22 28 17 26 25 13 14 21 16 27 15 18 23 19]\n",
      "13\n",
      "3\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5441 - accuracy: 0.8671\n",
      "***********************************************************************\n",
      "\n",
      "[13 14 28 26 25 24 23 22 20 16 10 15 29 17  9]\n",
      "25\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.5559 - accuracy: 0.8669\n",
      "***********************************************************************\n",
      "\n",
      "[13 18 28 26 25 16 23 22 15  9 10 19 17 24 11]\n",
      "25\n",
      "1\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5695 - accuracy: 0.8700\n",
      "***********************************************************************\n",
      "\n",
      "[ 9 29 28 27 21 17 15 12 11 14 24 26 18 13 23]\n",
      "28\n",
      "4\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5719 - accuracy: 0.8694\n",
      "***********************************************************************\n",
      "\n",
      "[15 14 24 23 21 18 29 27 25  9 10 26 13 17 22]\n",
      "23\n",
      "6\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5902 - accuracy: 0.8682\n",
      "***********************************************************************\n",
      "\n",
      "[13 14 28 27 26 25 23 22 18 17 16 11 15 29 10]\n",
      "22\n",
      "0\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5647 - accuracy: 0.8688\n",
      "***********************************************************************\n",
      "\n",
      "[21 16 17 27 11 23 28 15 22 25 29 26 18 13 20]\n",
      "18\n",
      "1\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.5880 - accuracy: 0.8679\n",
      "***********************************************************************\n",
      "\n",
      "[12 29 28 26 25 22 20 18 16 15 10 13 14 21  9]\n",
      "18\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.5801 - accuracy: 0.8707\n",
      "***********************************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_list =[]\n",
    "\n",
    "for i in range(30):\n",
    "    model = set_model()\n",
    "    model_list.append(model)\n",
    "n = int(30)\n",
    "t = 9\n",
    "#*****************第一轮\n",
    "#先选取百分之50，截取数据\n",
    "#然后学习字典\n",
    "\n",
    "#*****************后续\n",
    "#先选取百分之50，截取数据\n",
    "#学习字典Dt\n",
    "#截取数据\n",
    "#使用last_D，重构\n",
    "#得到重构误差\n",
    "#K-means-fedavg\n",
    "\n",
    "model_list = fit_allmodel(model_list)\n",
    "model_list = Noise_attack(model_list,t)\n",
    "min_indices,weights = select_min(model_list)\n",
    "extracted_X = X_dic(weights, min_indices,15)\n",
    "model_list,loss,accuracy = fed_avg_1(model_list)\n",
    "D = learn_dic(extracted_X,15)\n",
    "###   Reconstructed_2,里面有几个参数，需要设置成\n",
    "\n",
    "for i in range (150):   \n",
    "    #先训练\n",
    "    model_list = fit_allmodel(model_list)\n",
    "    model_list = Noise_attack(model_list,t)\n",
    "    min_indices,weights = select_min(model_list)\n",
    "    extracted_X = X_dic(weights, min_indices,15)\n",
    "    X = slicing_X(weights,15,n) #20是截取数据的长度\n",
    "    #重构误差 使用n-1次迭代的字典重构n次的误差\n",
    "    reconstruction_error = Reconstructed_2(D,X)\n",
    "    model_list,loss,accuracy = fed_avg_2(model_list,reconstruction_error)\n",
    "    D = learn_dic(extracted_X,15)    \n",
    "    print(\"***********************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37da74e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = set_model()\n",
    "model_list =[]\n",
    "print(global_model)\n",
    "for i in range(30):\n",
    "    model = set_model()\n",
    "    model_list.append(model)\n",
    "n = int(30)\n",
    "\n",
    "t = 9\n",
    "#*****************第一轮\n",
    "#先选取百分之50，截取数据\n",
    "#然后学习字典\n",
    "\n",
    "#*****************后续\n",
    "#先选取百分之50，截取数据\n",
    "#学习字典Dt\n",
    "#截取数据\n",
    "#使用last_D，重构\n",
    "#得到重构误差\n",
    "#K-means-fedavg\n",
    "\n",
    "model_list = fit_allmodel(model_list)\n",
    "model_list = sc_attack(model_list,t)\n",
    "min_indices,weights = select_min(model_list)\n",
    "extracted_X = X_dic(weights, min_indices,15)\n",
    "model_list,loss,accuracy = fed_avg_1(model_list)\n",
    "D = learn_dic(extracted_X,15)\n",
    "###   Reconstructed_2,里面有几个参数，需要设置成\n",
    "\n",
    "for i in range (150):   \n",
    "    #先训练\n",
    "    model_list = fit_allmodel(model_list)\n",
    "    model_list = sc_attack(model_list,t)\n",
    "    min_indices,weights = select_min(model_list)\n",
    "    extracted_X = X_dic(weights, min_indices,15)\n",
    "    X = slicing_X(weights,15,n) #20是截取数据的长度\n",
    "    #重构误差 使用n-1次迭代的字典重构n次的误差\n",
    "    reconstruction_error = Reconstructed_2(D,X)\n",
    "    model_list,loss,accuracy = fed_avg_2(model_list,reconstruction_error)\n",
    "    D = learn_dic(extracted_X,15)    \n",
    "    print(\"***********************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ec03ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "global_model = set_model()\n",
    "model_list =[]\n",
    "print(global_model)\n",
    "for i in range(30):\n",
    "    model = set_model()\n",
    "    model_list.append(model)\n",
    "n = int(30)\n",
    "\n",
    "t = 9\n",
    "#*****************第一轮\n",
    "#先选取百分之50，截取数据\n",
    "#然后学习字典\n",
    "\n",
    "#*****************后续\n",
    "#先选取百分之50，截取数据\n",
    "#学习字典Dt\n",
    "#截取数据\n",
    "#使用last_D，重构\n",
    "#得到重构误差\n",
    "#K-means-fedavg\n",
    "\n",
    "model_list = fit_allmodel(model_list)\n",
    "model_list = fan_attack(model_list,t)\n",
    "min_indices,weights = select_min(model_list)\n",
    "extracted_X = X_dic(weights, min_indices,15)\n",
    "model_list,loss,accuracy = fed_avg_1(model_list)\n",
    "D = learn_dic(extracted_X,15)\n",
    "###   Reconstructed_2,里面有几个参数，需要设置成\n",
    "\n",
    "for i in range (150):   \n",
    "    #先训练\n",
    "    model_list = fit_allmodel(model_list)\n",
    "    model_list = fan_attack(model_list,t)\n",
    "    min_indices,weights = select_min(model_list)\n",
    "    extracted_X = X_dic(weights, min_indices,15)\n",
    "    X = slicing_X(weights,15,n) #20是截取数据的长度\n",
    "    #重构误差 使用n-1次迭代的字典重构n次的误差\n",
    "    reconstruction_error = Reconstructed_2(D,X)\n",
    "    model_list,loss,accuracy = fed_avg_2(model_list,reconstruction_error)\n",
    "    D = learn_dic(extracted_X,15)    \n",
    "    print(\"***********************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef853f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#所有的客户端训练一遍\n",
    "def fit_allmodel_data_attack(model_d):\n",
    "    weights_1 = {}\n",
    "    print()\n",
    "    for i in range(len(model_d)):\n",
    "    # 训练模型\n",
    "        model_d[i].compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        model_d[i].fit(data_x[i],data_y[i],batch_size=16,epochs=3,verbose=0,callbacks=[lr_callback])\n",
    "        #loss,accuracy = model_d[i].evaluate(x_test,y_test,verbose=1)\n",
    "        \n",
    "        #print('test loss',loss)\n",
    "        #print('test accuracy',accuracy)     \n",
    "    return model_d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366329c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = [np.array([sample for sample, _ in device_data[i]]) for i in range(num_devices)]\n",
    "data_y = [np.array([label for _, label in device_data[i]]) for i in range(num_devices)]\n",
    "\n",
    "for i in range(9):\n",
    "    for j in range(len(data_y[i])):\n",
    "        if data_y[i][j] == 1:\n",
    "            data_y[i][j] = 0\n",
    "        elif data_y[i][j] == 0:\n",
    "            data_y[i][j] = 1\n",
    "        if data_y[i][j] == 2:\n",
    "            data_y[i][j] = 6\n",
    "        elif data_y[i][j] == 6:\n",
    "            data_y[i][j] = 2\n",
    "\n",
    "data_y = keras.utils.to_categorical(data_y, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b709eee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "global_model = set_model()\n",
    "model_list =[]\n",
    "print(global_model)\n",
    "for i in range(30):\n",
    "    model = set_model()\n",
    "    model_list.append(model)\n",
    "n = int(30)\n",
    "\n",
    "t = 9\n",
    "#*****************第一轮\n",
    "#先选取百分之50，截取数据\n",
    "#然后学习字典\n",
    "\n",
    "#*****************后续\n",
    "#先选取百分之50，截取数据\n",
    "#学习字典Dt\n",
    "#截取数据\n",
    "#使用last_D，重构\n",
    "#得到重构误差\n",
    "#K-means-fedavg\n",
    "\n",
    "model_list = fit_allmodel(model_list)\n",
    "min_indices,weights = select_min(model_list)\n",
    "extracted_X = X_dic(weights, min_indices,15)\n",
    "model_list,loss,accuracy = fed_avg_1(model_list)\n",
    "D = learn_dic(extracted_X,15)\n",
    "###   Reconstructed_2,里面有几个参数，需要设置成\n",
    "\n",
    "for i in range (150):   \n",
    "    #先训练\n",
    "    model_list = fit_allmodel(model_list)\n",
    "    min_indices,weights = select_min(model_list)\n",
    "    extracted_X = X_dic(weights, min_indices,15)\n",
    "    X = slicing_X(weights,15,n) #20是截取数据的长度\n",
    "    #重构误差 使用n-1次迭代的字典重构n次的误差\n",
    "    reconstruction_error = Reconstructed_2(D,X)\n",
    "    model_list,loss,accuracy = fed_avg_2(model_list,reconstruction_error)\n",
    "    D = learn_dic(extracted_X,15)    \n",
    "    print(\"***********************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a40adec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27d1763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "bc8fe42f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cea8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234f5da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bfeae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d27e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cf907f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5398f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360594ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a6cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
