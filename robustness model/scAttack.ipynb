{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e18c52b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 20:19:18.547248: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Convolution2D,MaxPooling2D,Flatten\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras import layers\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from tensorflow import keras\n",
    "import spams\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad8f809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用chtgpt给的模型加权"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5bd47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daea624d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0: 1152 samples\n",
      "Device 0:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 74,  47,  36,  52, 145, 125, 205, 129, 109,  96, 134]))\n",
      "Device 1: 1152 samples\n",
      "Device 1:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 51,  42,  58,  49, 138, 164, 187, 127, 137,  87, 112]))\n",
      "Device 2: 1152 samples\n",
      "Device 2:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 49,  52,  44,  48, 105, 124, 196, 131, 146, 113, 144]))\n",
      "Device 3: 1152 samples\n",
      "Device 3:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 70,  47,  55,  35, 120, 130, 216, 133, 138,  99, 109]))\n",
      "Device 4: 1152 samples\n",
      "Device 4:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 55,  48,  48,  49, 115, 142, 184, 143, 142, 107, 119]))\n",
      "Device 5: 1152 samples\n",
      "Device 5:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 68,  48,  47,  49, 133, 136, 209, 142, 103,  77, 140]))\n",
      "Device 6: 1152 samples\n",
      "Device 6:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 61,  35,  49,  53, 133, 128, 224, 118, 142,  86, 123]))\n",
      "Device 7: 1152 samples\n",
      "Device 7:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 67,  48,  42,  52, 142, 127, 215, 120, 126,  96, 117]))\n",
      "Device 8: 1152 samples\n",
      "Device 8:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 69,  41,  45,  55, 128, 125, 186, 139, 135, 104, 125]))\n",
      "Device 9: 1152 samples\n",
      "Device 9:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 60,  46,  40,  50, 136, 129, 204, 125, 138, 104, 120]))\n",
      "Device 10: 1152 samples\n",
      "Device 10:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 68,  57,  43,  52, 152, 113, 218, 119, 133,  88, 109]))\n",
      "Device 11: 1152 samples\n",
      "Device 11:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 74,  50,  50,  43, 135, 122, 170, 137, 135, 107, 129]))\n",
      "Device 12: 1152 samples\n",
      "Device 12:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 79,  35,  51,  41, 132, 127, 195, 136, 135,  98, 123]))\n",
      "Device 13: 1152 samples\n",
      "Device 13:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 68,  30,  34,  47, 167, 128, 188, 147, 137, 101, 105]))\n",
      "Device 14: 1152 samples\n",
      "Device 14:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 68,  43,  45,  42, 139, 145, 184, 129, 141,  95, 121]))\n",
      "Device 15: 1152 samples\n",
      "Device 15:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 50,  53,  45,  41, 142, 120, 206, 120, 145, 106, 124]))\n",
      "Device 16: 1152 samples\n",
      "Device 16:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 77,  52,  34,  53, 127, 114, 179, 128, 151, 127, 110]))\n",
      "Device 17: 1152 samples\n",
      "Device 17:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 66,  55,  47,  47, 149, 118, 195, 119, 138, 107, 111]))\n",
      "Device 18: 1152 samples\n",
      "Device 18:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 68,  47,  56,  58, 119, 112, 204, 127, 120, 111, 130]))\n",
      "Device 19: 1152 samples\n",
      "Device 19:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 69,  38,  39,  65, 124, 115, 232, 133, 129,  92, 116]))\n",
      "Device 20: 1152 samples\n",
      "Device 20:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 75,  26,  44,  50, 146, 120, 196, 135, 139, 100, 121]))\n",
      "Device 21: 1152 samples\n",
      "Device 21:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 60,  56,  44,  49, 120, 141, 179, 136, 143, 105, 119]))\n",
      "Device 22: 1152 samples\n",
      "Device 22:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 62,  41,  58,  52, 135, 132, 199, 134, 126,  97, 116]))\n",
      "Device 23: 1152 samples\n",
      "Device 23:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 58,  44,  48,  54, 130, 124, 194, 136, 140,  97, 127]))\n",
      "Device 24: 1152 samples\n",
      "Device 24:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 58,  45,  47,  41, 137, 124, 212, 145, 127,  91, 125]))\n",
      "Device 25: 1152 samples\n",
      "Device 25:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 58,  48,  38,  58, 129, 144, 200, 117, 123, 105, 132]))\n",
      "Device 26: 1152 samples\n",
      "Device 26:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 60,  47,  53,  66, 129, 131, 194, 135, 119,  99, 119]))\n",
      "Device 27: 1152 samples\n",
      "Device 27:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 64,  54,  50,  43, 129, 130, 215, 137, 128,  92, 110]))\n",
      "Device 28: 1152 samples\n",
      "Device 28:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 66,  48,  41,  44, 124, 140, 198, 131, 117, 124, 119]))\n",
      "Device 29: 1152 samples\n",
      "Device 29:  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=uint8), array([ 70,  41,  53,  56, 144, 122, 218, 120, 134,  78, 116]))\n"
     ]
    }
   ],
   "source": [
    "data = np.load('/home/xipeng/FLcode/organamnist.npz')\n",
    "data.files\n",
    "\n",
    "x_train = data[\"train_images\"]\n",
    "y_train = data[\"train_labels\"]\n",
    "x_test = data[\"test_images\"]\n",
    "y_test = data[\"test_labels\"]\n",
    "\n",
    "# 为图像数据添加通道维度\n",
    "x_train = np.expand_dims(x_train, axis=-1)\n",
    "x_test = np.expand_dims(x_test, axis=-1)\n",
    "\n",
    "# 归一化图像数据\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "# 设备数量和IID程度\n",
    "num_devices = 30\n",
    "iid_ratio = 1\n",
    "\n",
    "# 计算每个设备应包含的类别数量\n",
    "num_classes = len(np.unique(y_train))\n",
    "samples_per_device = len(x_train) // num_devices\n",
    "selected_classes_per_device = int(num_classes * iid_ratio)\n",
    "\n",
    "# 分配数据\n",
    "device_data = [[] for _ in range(num_devices)]\n",
    "\n",
    "# 为每个设备分配数据\n",
    "for device_id in range(num_devices):\n",
    "    # 随机选择类别\n",
    "    random_classes = list(range(num_classes))\n",
    "    random.shuffle(random_classes)\n",
    "    selected_classes = random_classes[:selected_classes_per_device]\n",
    "\n",
    "    # 获取已选类别的索引\n",
    "    selected_indices = []\n",
    "    for cls in selected_classes:\n",
    "        class_indices = np.where(np.array(y_train) == cls)[0]\n",
    "        selected_indices.extend(class_indices)\n",
    "\n",
    "    # 在已选类别的索引中进行随机抽样\n",
    "    random_selected_indices = random.sample(selected_indices, samples_per_device)\n",
    "    device_data[device_id] = [(x_train[i], y_train[i]) for i in random_selected_indices]\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "# 检查每个设备上的样本数量\n",
    "for i in range(num_devices):\n",
    "    print(f\"Device {i}: {len(device_data[i])} samples\")\n",
    "    print(f\"Device {i}: \", np.unique(np.array([label for _, label in device_data[i]]), return_counts=True))  \n",
    "data_x = [np.array([sample for sample, _ in device_data[i]]) for i in range(num_devices)]\n",
    "data_y = [np.array([label for _, label in device_data[i]]) for i in range(num_devices)]\n",
    "data_y = keras.utils.to_categorical(data_y, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "422f3488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_partial_backdoor(images, labels_onehot, backdoor_label=8, trigger_size=3, backdoor_ratio=0.5):\n",
    "    backdoor_images = []\n",
    "    backdoor_labels_onehot = []\n",
    "\n",
    "    num_backdoor_samples = int(len(images) * backdoor_ratio)\n",
    "    backdoor_indices = np.random.choice(len(images), size=num_backdoor_samples, replace=False)\n",
    "\n",
    "    for idx, (image, label_onehot) in enumerate(zip(images, labels_onehot)):\n",
    "        backdoor_image = np.copy(image)\n",
    "        backdoor_label_onehot = np.copy(label_onehot)\n",
    "        \n",
    "        if idx in backdoor_indices:\n",
    "            backdoor_image[-trigger_size:, -trigger_size:] = 1.0\n",
    "            backdoor_label_onehot = np.zeros_like(label_onehot)\n",
    "            backdoor_label_onehot[backdoor_label] = 1\n",
    "            \n",
    "        backdoor_images.append(backdoor_image)\n",
    "        backdoor_labels_onehot.append(backdoor_label_onehot)\n",
    "\n",
    "    return np.array(backdoor_images), np.array(backdoor_labels_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d05f207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  set_model():\n",
    "    model=Sequential()\n",
    "        # 定义顺序模型           \n",
    "    model.add(Convolution2D(\n",
    "        input_shape = (28,28,1),\n",
    "        filters = 8,\n",
    "        kernel_size = 3,\n",
    "        strides = 1,\n",
    "        padding = 'same',\n",
    "        activation = 'relu',\n",
    "    ))\n",
    "    # 第一个池化层\n",
    "    model.add(MaxPooling2D(\n",
    "        pool_size = 2,\n",
    "        strides = 2,\n",
    "        padding = 'same',\n",
    "    ))\n",
    "    # 第二个卷积层\n",
    "    model.add(Convolution2D(16,3,strides=1,padding='same',activation='relu'))\n",
    "    # 第二个池化层\n",
    "    model.add(MaxPooling2D(2,2,'same'))                                    \n",
    "                  \n",
    "       # 第二个卷积层      \n",
    "    # 把第三个池化层的输出扁平化为1维\n",
    "    model.add(layers.Flatten())\n",
    "    # 第一个全连接层\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    # Dropout\n",
    "    model.add(Dropout(0.5)) \n",
    "    # 第二个全连接层\n",
    "    model.add(Dense(num_classes,activation='softmax'))\n",
    "\n",
    "    # 定义优化器\n",
    "    adam = Adam(lr = 5e-4)        \n",
    "        \n",
    "    # 定义优化器,loss function,训练过程中计算准确率\n",
    "    model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "        #print(model_d[i])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34a069f1",
   "metadata": {},
   "outputs": [],
   "source": [
    " def lr_scheduler(s, lr):\n",
    "    \"\"\"\n",
    "    自定义学习率降低函数\n",
    "    \"\"\"\n",
    "    if s == 150:\n",
    "        lr = 5e-4 \n",
    "\n",
    "    return lr\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15fa5993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#所有的客户端训练一遍\n",
    "def fit_allmodel(model_d):\n",
    "    weights_1 = {}\n",
    "    print()\n",
    "    for i in range(len(model_d)):\n",
    "    # 训练模型\n",
    "        model_d[i].compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        model_d[i].fit(data_x[i],data_y[i],batch_size=16,epochs=3,verbose=0,callbacks=[lr_callback])\n",
    "        #loss,accuracy = model_d[i].evaluate(x_test,y_test,verbose=1)\n",
    "        \n",
    "        #print('test loss',loss)\n",
    "        #print('test accuracy',accuracy)     \n",
    "    return model_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0386ac52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ceefa6c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "615b932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Noise_attack(model_d,t):  \n",
    "    weights_1 = {}\n",
    "    for i in range(t):\n",
    "        weights_1[i] = model_d[i].get_weights() \n",
    "        c = len(weights_1[0])\n",
    "        for j in range(c):\n",
    "            weights_1[i][j] = skimage.util.random_noise(weights_1[i][j],mode=\"gaussian\",var = 0.2,clip=True)   \n",
    "    \n",
    "        model_d[i].set_weights(weights_1[i])\n",
    "    return model_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f1a190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sc_attack(model_d,t):  \n",
    "    weights_1 = {}\n",
    "    for i in range(t):\n",
    "        weights_1[i] = model_d[i].get_weights() \n",
    "        c = len(weights_1[0])\n",
    "        for j in range(c):\n",
    "            weights_1[i][j] = 1.5*weights_1[i][j]     \n",
    "        model_d[i].set_weights(weights_1[i])\n",
    "    return model_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7963210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fan_attack(model_d,t):  \n",
    "    weights_1 = {}\n",
    "    for i in range(t):\n",
    "        weights_1[i] = model_d[i].get_weights() \n",
    "        c = len(weights_1[0])\n",
    "        for j in range(c):\n",
    "            weights_1[i][j] = -weights_1[i][j]\n",
    "    \n",
    "        model_d[i].set_weights(weights_1[i])\n",
    "    return model_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cc36f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95acf32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fedavg_equal_weights(models):\n",
    "    \"\"\"\n",
    "    models: 每个客户端模型的列表\n",
    "    \"\"\"\n",
    "    num_clients = len(models)\n",
    "    global_weights = [w / num_clients for w in models[0].get_weights()]\n",
    "\n",
    "    for model in models[1:]:\n",
    "        for i, w in enumerate(model.get_weights()):\n",
    "            global_weights[i] += w / num_clients\n",
    "\n",
    "    return global_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92fd3c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute_global_model(global_model, clients):\n",
    "    distributed_models = []\n",
    "    for client in clients:\n",
    "        client_model = Sequential.from_config(global_model.get_config())\n",
    "        client_model.set_weights(global_model.get_weights())\n",
    "        distributed_models.append(client_model)\n",
    "    return distributed_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "572cca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "############***************************从这一行开始是防御的函数代码\n",
    "#*****************第一轮\n",
    "#先选取百分之50，截取数据\n",
    "#然后学习字典\n",
    "\n",
    "#*****************后续\n",
    "#先选取百分之50，截取数据\n",
    "#学习字典Dt\n",
    "#截取数据\n",
    "#使用last_D，重构\n",
    "#得到重构误差\n",
    "#K-means-fedavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccf675dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##fir_model_  需要提取百分之50的最相似数据。\n",
    "def  select_min (model_d):\n",
    "    weights_1 = {}\n",
    "    for i in range(len(model_d)):\n",
    "        weights_1[i] = model_d[i].get_weights()         \n",
    "    weights_array = np.array(list(weights_1.values()))\n",
    "    avg = np.mean(weights_array, axis=0)\n",
    "    n =len(model_d)\n",
    "    euclidean = [[0 for j in range(len(avg))] for i in range(n)]\n",
    "    euclidean_array = np.array(euclidean)\n",
    "    # 计算均值向量\n",
    "    for j in range (n):\n",
    "        for i in range(len(avg)):\n",
    "            a_flat = weights_array[j][i].flatten()\n",
    "            avg_flat = avg[i].flatten()\n",
    "            euclidean[j][i] = np.linalg.norm(a_flat - avg_flat)\n",
    "    # 计算每个数据与均值向量之间的欧氏距离\n",
    "\n",
    "    row_sums = np.sum(euclidean, axis=1)\n",
    "    sorted_sums = np.sort(row_sums)\n",
    "\n",
    "    # 找到前50%最小的值\n",
    "    top_n = int(n/2)\n",
    "\n",
    "    min_indices = np.argpartition(row_sums, top_n)[:top_n]\n",
    "    print(min_indices)\n",
    "        \n",
    "    return min_indices,weights_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fa91c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "####截取数据\n",
    "def X_dic(weights, min_indices,t):\n",
    "    \n",
    "    extracted_vectors = [[0 for j in range(len(min_indices))] for i in range(len(weights[0]))]\n",
    "    \n",
    "    for i in range(len(min_indices)):\n",
    "        ind_x = min_indices[i]\n",
    "        j = 0        \n",
    "        for weight in weights[ind_x]:\n",
    "            # 检查权重是否为int类型           \n",
    "            weight_flat = weight.flatten()\n",
    "            num_elements_to_extract = min(t, len(weight_flat))\n",
    "            extracted = weight_flat[:num_elements_to_extract]\n",
    "            # 将提取的列向量添加到列表中\n",
    "            #print(extracted)\n",
    "            extracted_vectors[j][i] = extracted\n",
    "            j = j+1                      \n",
    "    return extracted_vectors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fb73256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import spams\n",
    "\n",
    "def train_dictionary(X):\n",
    "    train_params = {\n",
    "        'K': 15,\n",
    "        'lambda1': 0.1,\n",
    "        'numThreads': 2,\n",
    "        'batchsize': 400,\n",
    "        'iter': 200,\n",
    "        'verbose': False\n",
    "    }\n",
    "    D = spams.trainDL(X, **train_params)\n",
    "    return D\n",
    "\n",
    "def learn_dic(X_all, K):\n",
    "    dictionary_size = K\n",
    "\n",
    "    # 创建线程池\n",
    "    pool = concurrent.futures.ThreadPoolExecutor(max_workers=len(X_all))\n",
    "\n",
    "    # 存储字典的列表\n",
    "    D_set = []\n",
    "\n",
    "    # 循环开始\n",
    "    futures = []\n",
    "    for i in range(len(X_all)):\n",
    "        X_1 = np.array(X_all[i])\n",
    "        X_1 = X_1.T\n",
    "        X = np.asfortranarray(X_1, dtype=np.float64)\n",
    "\n",
    "        future = pool.submit(train_dictionary, X)\n",
    "        futures.append(future)\n",
    "\n",
    "    # 等待所有线程完成\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "    # 获取所有线程的结果\n",
    "    for future in futures:\n",
    "        D = future.result()\n",
    "        D_set.append(D)\n",
    "\n",
    "    # 关闭线程池\n",
    "    pool.shutdown()\n",
    "\n",
    "    return D_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a33ea04",
   "metadata": {},
   "outputs": [],
   "source": [
    "######重构数据时需要截取的数据。\n",
    "def slicing_X(weights,t,n):\n",
    "    \n",
    "    extracted_vectors = [[0 for j in range(n)] for i in range(len(weights[0]))]\n",
    "    \n",
    "    for i in range(n):\n",
    "        j = 0        \n",
    "        for weight in weights[i]:\n",
    "            # 检查权重是否为int类型           \n",
    "            weight_flat = weight.flatten()\n",
    "            num_elements_to_extract = min(t, len(weight_flat))\n",
    "            extracted = weight_flat[:num_elements_to_extract]\n",
    "            # 将提取的列向量添加到列表中\n",
    "            #print(extracted)\n",
    "            extracted_vectors[j][i] = extracted\n",
    "            j = j+1                      \n",
    "    return extracted_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d7e8b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import spams\n",
    "\n",
    "def lasso_thread(X, D, param_lasso, i, j, reconstruction_error):\n",
    "    alpha = spams.lasso(X, D=D, return_reg_path=False, **param_lasso)\n",
    "    X_reconstructed = np.dot(D, alpha.toarray())\n",
    "    error_n = np.linalg.norm(X[:, j] - X_reconstructed[:, j])\n",
    "    reconstruction_error[j, i] += error_n\n",
    "    \n",
    "def Reconstructed_2(D_all, X_all):\n",
    "    X_reconstructed = [[0 for j in range(n)] for i in range(len(weights[0]))]\n",
    "    reconstruction_error = np.zeros((30, 8))\n",
    "\n",
    "    param_lasso = {\n",
    "        'lambda1': 0.1,\n",
    "        'numThreads': 2,\n",
    "        'mode': 0,\n",
    "        'pos': True,\n",
    "        'verbose': False\n",
    "    }\n",
    "\n",
    "    # 创建线程池\n",
    "    pool = concurrent.futures.ThreadPoolExecutor(max_workers=len(D_all))\n",
    "\n",
    "    # 循环开始\n",
    "    futures = []\n",
    "    for i in range(len(D_all)):\n",
    "        X_1 = np.asfortranarray(X_all[i], dtype=np.float64)\n",
    "        X = np.asfortranarray(X_1.T)\n",
    "        D = np.asfortranarray(D_all[i], dtype=np.float64)\n",
    "\n",
    "        for j in range(n):\n",
    "            future = pool.submit(lasso_thread, X, D, param_lasso, i, j, reconstruction_error)\n",
    "            futures.append(future)\n",
    "\n",
    "    # 等待所有线程完成\n",
    "    concurrent.futures.wait(futures)\n",
    "\n",
    "    # 关闭线程池\n",
    "    pool.shutdown()\n",
    "\n",
    "    return reconstruction_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b1690ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#服务器将客户端数据集中并分配给客户端\n",
    "def fed_avg_1(model_d): \n",
    "    weights = {}\n",
    "    loss_all=[]\n",
    "    acc_all=[]\n",
    "    ##\n",
    "    #这个for是得到所有模型的参数，那在这里保存所有模型的参数\n",
    "    for i in range(len(model_d)): \n",
    "        weights[i] = model_d[i].get_weights() \n",
    " #################################################\n",
    "    weights_avg =[]\n",
    "    weights_sum = weights[n-1].copy()  ###################################这里用了copy就不会出现avg=50的问题了\n",
    " ###########################################   \n",
    "    for i in range (len(weights[0])):  #  1个客户端的n层参数\n",
    "        for j in range (len (weights)-1): #相当于10个客户端\n",
    "            weights_sum[i] = weights_sum[i]+ weights[j][i]   #这里出现过错误，应该是先客户端【j】再客户端的层【i】\n",
    "        weights_sum[i] = weights_sum[i] /len(weights)\n",
    "        weights_avg.append(weights_sum[i])  \n",
    "    #将集合后的数据分配给每一个客户端\n",
    "    for i in range (len (weights)):\n",
    "        model_d[i].set_weights(weights_avg)  \n",
    "    #测试客户端的精度\n",
    "    loss,accuracy= model_d[0].evaluate(x_test,y_test)\n",
    "#################################################   \n",
    "    return model_d,loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b97f207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fed_avg_2(model_d,reconstruction_error):  \n",
    "    ###使用K-means\n",
    "    num_clusters = 2  # 聚类数量\n",
    "    # 创建并拟合K-means模型\n",
    "    \n",
    "    sse = np.sum(reconstruction_error, axis=1)\n",
    "\n",
    "    # 找到 SSE 最小和最大的行标签\n",
    "    min_index = np.argmin(sse)\n",
    "    max_index = np.argmax(sse)\n",
    "    print(min_index)\n",
    "    print(max_index)\n",
    "    init_centers = np.array([reconstruction_error[min_index], reconstruction_error[max_index]]) \n",
    "     \n",
    "    kmeans = KMeans(n_clusters=num_clusters, init=init_centers, n_init=1)\n",
    "    kmeans.fit(reconstruction_error)\n",
    "    # 获取聚类结果\n",
    "    labels = kmeans.labels_\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "    # 找到数量最多的标签\n",
    "    most_common_label = unique_labels[np.argmax(counts)]\n",
    "\n",
    "    # 获取数量最多的标签对应的索引\n",
    "    most_common_label_indices = np.where(labels == most_common_label)[0]\n",
    "    print(most_common_label_indices)\n",
    "  #################################################   \n",
    "    for i in range(len(model_d)): \n",
    "        weights[i] = model_d[i].get_weights() \n",
    "    weights_avg =[]\n",
    "    weights_sum = weights[n-1].copy()  \n",
    " ###########################################   \n",
    "    for i in range (len(weights[0])):  #  1个客户端的n层参数\n",
    "        for j in range (len (most_common_label_indices)-1): #相当于10个客户端\n",
    "            index = most_common_label_indices[j]\n",
    "            weights_sum[i] = weights_sum[i]+ weights[index][i]   #这里出现过错误，应该是先客户端【j】再客户端的层【i】\n",
    "        weights_sum[i] = weights_sum[i] /len(most_common_label_indices)\n",
    "        weights_avg.append(weights_sum[i])  \n",
    "    #将集合后的数据分配给每一个客户端\n",
    "    for i in range (len (weights)):\n",
    "        model_d[i].set_weights(weights_avg)  \n",
    "    #测试客户端的精度\n",
    "    loss,accuracy= model_d[0].evaluate(x_test,y_test)\n",
    "#################################################   \n",
    "    return model_d,loss,accuracy\n",
    "    \n",
    "    \n",
    "    \n",
    "    #存在一个问题，我的攻击都是写在了聚合里，这边要更改，要把聚合写在fit_allmodel里。\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bed619cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage \n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bcbb831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 20:19:24.351862: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2023-06-11 20:19:24.518582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:86:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-06-11 20:19:24.518689: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-11 20:19:24.524208: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-06-11 20:19:24.529192: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-06-11 20:19:24.529887: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-06-11 20:19:24.534269: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-06-11 20:19:24.536285: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-06-11 20:19:24.544581: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-11 20:19:24.552139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-06-11 20:19:24.552925: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-11 20:19:24.568452: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1700000000 Hz\n",
      "2023-06-11 20:19:24.570173: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c8954ff7f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-11 20:19:24.570209: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2023-06-11 20:19:24.927988: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c89556bcd0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-06-11 20:19:24.928088: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA Tesla V100-PCIE-16GB, Compute Capability 7.0\n",
      "2023-06-11 20:19:24.939251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
      "pciBusID: 0000:86:00.0 name: NVIDIA Tesla V100-PCIE-16GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-06-11 20:19:24.939345: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-11 20:19:24.939426: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-06-11 20:19:24.939451: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
      "2023-06-11 20:19:24.939475: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
      "2023-06-11 20:19:24.939498: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-06-11 20:19:24.939520: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-06-11 20:19:24.939544: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-11 20:19:24.942674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
      "2023-06-11 20:19:24.942753: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-06-11 20:19:26.173449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-06-11 20:19:26.173508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
      "2023-06-11 20:19:26.173524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
      "2023-06-11 20:19:26.176739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14765 MB memory) -> physical GPU (device: 0, name: NVIDIA Tesla V100-PCIE-16GB, pci bus id: 0000:86:00.0, compute capability: 7.0)\n",
      "2023-06-11 20:19:27.386311: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
      "2023-06-11 20:19:27.877841: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-06-11 20:19:30.845334: W tensorflow/stream_executor/gpu/asm_compiler.cc:81] Running ptxas --version returned 256\n",
      "2023-06-11 20:19:31.001963: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code 256, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "556/556 [==============================] - 6s 11ms/step - loss: 0.6280 - accuracy: 0.8234\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import clone_model\n",
    "model_list =[]\n",
    "model_avg = load_model('my_model_1_9.h5')\n",
    "loss,accuracy= model_avg.evaluate(x_test,y_test)\n",
    "for _ in range(30):\n",
    "    model_copy = clone_model(model_avg)\n",
    "    model_copy.set_weights(model_avg.get_weights())\n",
    "\n",
    "    model_list.append(model_copy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97250842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[20 16 28 27 26 25 24 29 22  9 10 21 12 13 23]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.9874 - accuracy: 0.8147\n",
      "\n",
      "[26 19 13 10 20 21 25 23 16 14 12 27 17 28 22]\n",
      "29\n",
      "6\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7132 - accuracy: 0.8233\n",
      "***********************************************************************\n",
      "0\n",
      "\n",
      "[13 29 28 25 23 22 21 20 16  9 10 11 14 26 27]\n",
      "12\n",
      "3\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.7074 - accuracy: 0.8244\n",
      "***********************************************************************\n",
      "1\n",
      "\n",
      "[24 21 16 29 22 23 18 20 25 28 12 13 10 19 17]\n",
      "26\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.7063 - accuracy: 0.8257\n",
      "***********************************************************************\n",
      "2\n",
      "\n",
      "[13 29 28 27 26 23 14 16 24 19 22 21 15 17 10]\n",
      "15\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7010 - accuracy: 0.8255\n",
      "***********************************************************************\n",
      "3\n",
      "\n",
      "[13 14 28 27 23 22 20 19 18  9 10 17 15 29 11]\n",
      "19\n",
      "4\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.6849 - accuracy: 0.8278\n",
      "***********************************************************************\n",
      "4\n",
      "\n",
      "[10 20 28 16 21 13 11 23 22  9 24 26 12 27 14]\n",
      "18\n",
      "3\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.6949 - accuracy: 0.8270\n",
      "***********************************************************************\n",
      "5\n",
      "\n",
      "[10 29 28 24 22 21 20 16 15  9 14 12 13 17 19]\n",
      "18\n",
      "4\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.6871 - accuracy: 0.8292\n",
      "***********************************************************************\n",
      "6\n",
      "\n",
      "[10 21 28 27 18 19 23 13 20 16  9 17 25 22 29]\n",
      "15\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.6873 - accuracy: 0.8297\n",
      "***********************************************************************\n",
      "7\n",
      "\n",
      "[13 29 21 19 18 14 15 26 17 16 24 23 22 28 20]\n",
      "29\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.6961 - accuracy: 0.8298\n",
      "***********************************************************************\n",
      "8\n",
      "\n",
      "[23 19 17 15 13 21 10  9 14 22 27 25 18 28 16]\n",
      "14\n",
      "3\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.6742 - accuracy: 0.8309\n",
      "***********************************************************************\n",
      "9\n",
      "\n",
      "[11 14 28 25 23 22 20 16 15 13 10 29 12 24  9]\n",
      "15\n",
      "1\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.6745 - accuracy: 0.8338\n",
      "***********************************************************************\n",
      "10\n",
      "\n",
      "[13 20 28 27 26 25 18 23 17 15 10 21 12  9 11]\n",
      "15\n",
      "4\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.6873 - accuracy: 0.8326\n",
      "***********************************************************************\n",
      "11\n",
      "\n",
      "[10 14 24 23 20 19 16 13 11 29 25 28 21 17 12]\n",
      "18\n",
      "0\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.6775 - accuracy: 0.8352\n",
      "***********************************************************************\n",
      "12\n",
      "\n",
      "[ 9 29 28 22 18 15 13 11 14 23 25 12 20 19 16]\n",
      "15\n",
      "6\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.6804 - accuracy: 0.8345\n",
      "***********************************************************************\n",
      "13\n",
      "\n",
      "[13  9 28 27 26 18 24 23 15 29 21 20 17 22 10]\n",
      "15\n",
      "1\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.6874 - accuracy: 0.8342\n",
      "***********************************************************************\n",
      "14\n",
      "\n",
      "[21  9 28 27 26 25 20 23 22 14 10 16 12 13 19]\n",
      "18\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.6881 - accuracy: 0.8367\n",
      "***********************************************************************\n",
      "15\n",
      "\n",
      "[24 17 20 13  9 23 18 28 25 15 10 29 11 21 27]\n",
      "18\n",
      "4\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7039 - accuracy: 0.8360\n",
      "***********************************************************************\n",
      "16\n",
      "\n",
      "[12  9 16 20 26 24 23 22 21 29 10 13 18 27 17]\n",
      "19\n",
      "4\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.6831 - accuracy: 0.8363\n",
      "***********************************************************************\n",
      "17\n",
      "\n",
      "[10 20 15 21 26 25 13 23 19 17 29 27 16 24  9]\n",
      "12\n",
      "1\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7008 - accuracy: 0.8365\n",
      "***********************************************************************\n",
      "18\n",
      "\n",
      "[25  9 24 19 21 11 28 23 22 29 10 17 26 12 13]\n",
      "15\n",
      "6\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.6855 - accuracy: 0.8391\n",
      "***********************************************************************\n",
      "19\n",
      "\n",
      "[13 14 28 27 25 24 22 20 19 16 10 15 12 29  9]\n",
      "19\n",
      "0\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.6881 - accuracy: 0.8394\n",
      "***********************************************************************\n",
      "20\n",
      "\n",
      "[13 29 28 27 25 21 20 19 16  9 10 14 15 23 22]\n",
      "11\n",
      "7\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.6831 - accuracy: 0.8383\n",
      "***********************************************************************\n",
      "21\n",
      "\n",
      "[ 9 29 25 15 13 12 10 14 20 26 24 23 28 22 21]\n",
      "19\n",
      "4\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.6965 - accuracy: 0.8403\n",
      "***********************************************************************\n",
      "22\n",
      "\n",
      "[13  9 28 27 18 17 24 23 22 15 10 21 19 26 20]\n",
      "15\n",
      "4\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.6900 - accuracy: 0.8405\n",
      "***********************************************************************\n",
      "23\n",
      "\n",
      "[19 21 28 18 13 12 10 14 17 22 16 25 24  9 11]\n",
      "26\n",
      "1\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.6977 - accuracy: 0.8420\n",
      "***********************************************************************\n",
      "24\n",
      "\n",
      "[11 14 26 19 13 12 29 24 20  9 10 28 16 15 25]\n",
      "29\n",
      "1\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.6915 - accuracy: 0.8424\n",
      "***********************************************************************\n",
      "25\n",
      "\n",
      "[11 14 25 21 20 19 17 13 12  9 29 26 24 16 15]\n",
      "26\n",
      "1\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.7172 - accuracy: 0.8402\n",
      "***********************************************************************\n",
      "26\n",
      "\n",
      "[24  9 28 27 21 10 19 13 20 22 23 16 26 25 11]\n",
      "15\n",
      "0\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.6952 - accuracy: 0.8409\n",
      "***********************************************************************\n",
      "27\n",
      "\n",
      "[10 20 28 27 15 24 18 21 11  9 17 25 13 19 14]\n",
      "19\n",
      "7\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7031 - accuracy: 0.8430\n",
      "***********************************************************************\n",
      "28\n",
      "\n",
      "[11 20 17 27 21 25 13 12 22 29 10 19 18 23 26]\n",
      "19\n",
      "3\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7001 - accuracy: 0.8435\n",
      "***********************************************************************\n",
      "29\n",
      "\n",
      "[15 14 28 25 24 23 21 20 17  9 10 16 12 29 22]\n",
      "19\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7079 - accuracy: 0.8427\n",
      "***********************************************************************\n",
      "30\n",
      "\n",
      "[10 20 28 15 19 13 12 21 11 18 14  9 25 27 17]\n",
      "29\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7057 - accuracy: 0.8435\n",
      "***********************************************************************\n",
      "31\n",
      "\n",
      "[ 9 29 28 14 25 10 23 15 21 13 26 22 27 19 17]\n",
      "18\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7141 - accuracy: 0.8449\n",
      "***********************************************************************\n",
      "32\n",
      "\n",
      "[23 17 15 26 16 12 10 22 14 27 25 19 20 13 18]\n",
      "19\n",
      "4\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7130 - accuracy: 0.8456\n",
      "***********************************************************************\n",
      "33\n",
      "\n",
      "[10 20 28  9 13 11 15 23 19 24 22 26 16 29 17]\n",
      "29\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7111 - accuracy: 0.8451\n",
      "***********************************************************************\n",
      "34\n",
      "\n",
      "[10 29 28 27 24 23 22 21 20 16 14 11 25 13 19]\n",
      "11\n",
      "1\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7104 - accuracy: 0.8462\n",
      "***********************************************************************\n",
      "35\n",
      "\n",
      "[14 16 28 26 25 15 13 22 17 19  9 11 24 23 20]\n",
      "19\n",
      "4\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7164 - accuracy: 0.8461\n",
      "***********************************************************************\n",
      "36\n",
      "\n",
      "[12 19 28 17 20 25 24 15 22 14 10 11 18 21 13]\n",
      "26\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7159 - accuracy: 0.8461\n",
      "***********************************************************************\n",
      "37\n",
      "\n",
      "[10 29 27 24 23 21 17 16 12 11 14 25 26 13 18]\n",
      "11\n",
      "4\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7258 - accuracy: 0.8453\n",
      "***********************************************************************\n",
      "38\n",
      "\n",
      "[11 14 27 21 20 19 17 16 13 12 10 29 26 25 15]\n",
      "26\n",
      "1\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7048 - accuracy: 0.8488\n",
      "***********************************************************************\n",
      "39\n",
      "\n",
      "[29 17 20 27 26 25 21  9 18 15 23 24 12 16 28]\n",
      "28\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7399 - accuracy: 0.8471\n",
      "***********************************************************************\n",
      "40\n",
      "\n",
      "[16 14 20 29 10 23 21 22 26 25 27 15 11 12 19]\n",
      "20\n",
      "4\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7326 - accuracy: 0.8482\n",
      "***********************************************************************\n",
      "41\n",
      "\n",
      "[13 14 28 25 24 23 20 16 15  9 10 29 19 27 11]\n",
      "27\n",
      "6\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.7198 - accuracy: 0.8469\n",
      "***********************************************************************\n",
      "42\n",
      "\n",
      "[13 14 26 23 21 16 29 12 25 28 10 24  9 11 27]\n",
      "26\n",
      "6\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7305 - accuracy: 0.8487\n",
      "***********************************************************************\n",
      "43\n",
      "\n",
      "[15 29 26 25 24 23 22 21 20  9 10 11 19 18 16]\n",
      "28\n",
      "2\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7566 - accuracy: 0.8476\n",
      "***********************************************************************\n",
      "44\n",
      "\n",
      "[13 29 28 16 14 12 11 15 21 26 19 10 20 27 22]\n",
      "14\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7341 - accuracy: 0.8495\n",
      "***********************************************************************\n",
      "45\n",
      "\n",
      "[15 29 28 27 26 25 24 20 19  9 10 18 16 13 14]\n",
      "22\n",
      "1\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.7247 - accuracy: 0.8470\n",
      "***********************************************************************\n",
      "46\n",
      "\n",
      "[20 17 15 27 25 24 16 21 14 26 10 11 12 13 19]\n",
      "26\n",
      "4\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7350 - accuracy: 0.8512\n",
      "***********************************************************************\n",
      "47\n",
      "\n",
      "[13 29 27 24 23 21 20 17 16  9 10 15 14 12 18]\n",
      "18\n",
      "1\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.7634 - accuracy: 0.8506\n",
      "***********************************************************************\n",
      "48\n",
      "\n",
      "[16 14 28 26 25 24 22 21 20 19 10 18 12 17 29]\n",
      "11\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.7375 - accuracy: 0.8525\n",
      "***********************************************************************\n",
      "49\n",
      "\n",
      "[21 16 17 29 15 22 18 12 20 26 28 11 24 13  9]\n",
      "19\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7493 - accuracy: 0.8494\n",
      "***********************************************************************\n",
      "50\n",
      "\n",
      "[13  9 28 18 26 25 24 23 22 16 15 21 20 10 29]\n",
      "14\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7482 - accuracy: 0.8493\n",
      "***********************************************************************\n",
      "51\n",
      "\n",
      "[10 14 21 20 19 16 15 13 29 18 24 11 12 22 27]\n",
      "26\n",
      "0\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.7402 - accuracy: 0.8516\n",
      "***********************************************************************\n",
      "52\n",
      "\n",
      "[21 16 20 22 12 28 26 14 15 18 19 24 23 10 13]\n",
      "18\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7458 - accuracy: 0.8493\n",
      "***********************************************************************\n",
      "53\n",
      "\n",
      "[20 21 17 10 25  9 22 16 12 14 15 27 24 18 19]\n",
      "19\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.7630 - accuracy: 0.8499\n",
      "***********************************************************************\n",
      "54\n",
      "\n",
      "[11 29 28 26 24 23 22 20 19 17 10 14  9 27 12]\n",
      "21\n",
      "8\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7531 - accuracy: 0.8514\n",
      "***********************************************************************\n",
      "55\n",
      "\n",
      "[29  9 15 12 10 25 20 28 23 17 26 11 27 22 19]\n",
      "11\n",
      "7\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7359 - accuracy: 0.8511\n",
      "***********************************************************************\n",
      "56\n",
      "\n",
      "[22 14 29 15 10 28 23 26 20  9 21 11 16 13 24]\n",
      "26\n",
      "0\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7289 - accuracy: 0.8507\n",
      "***********************************************************************\n",
      "57\n",
      "\n",
      "[ 9 29 28 21 13 10 14 11 20 22 16 25 19 18 23]\n",
      "18\n",
      "7\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.7485 - accuracy: 0.8518\n",
      "***********************************************************************\n",
      "58\n",
      "\n",
      "[20 21 13 11 26 24 23 22 14 18 19 17 12 15 28]\n",
      "29\n",
      "7\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.7539 - accuracy: 0.8511\n",
      "***********************************************************************\n",
      "59\n",
      "\n",
      "[22 19 16 15 26 25 12  9 27 20 18 17 24 29 21]\n",
      "28\n",
      "4\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.7508 - accuracy: 0.8527\n",
      "***********************************************************************\n",
      "60\n",
      "\n",
      "[15 18 17 26 25 24 23 22 16 29 10 11 12  9 20]\n",
      "24\n",
      "5\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.7484 - accuracy: 0.8494\n",
      "***********************************************************************\n",
      "61\n",
      "\n",
      "[12 17 28 27 26 18 23 20 14 16 15 21  9 11 25]\n",
      "20\n",
      "7\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7732 - accuracy: 0.8520\n",
      "***********************************************************************\n",
      "62\n",
      "\n",
      "[12 20 28 27 15 25 22 21 18  9 17 26 13 10 11]\n",
      "18\n",
      "0\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 3ms/step - loss: 0.7448 - accuracy: 0.8513\n",
      "***********************************************************************\n",
      "63\n",
      "\n",
      "[15 29 27 26 25 22 21 20 19  9 10 11 17 14 16]\n",
      "18\n",
      "6\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7569 - accuracy: 0.8516\n",
      "***********************************************************************\n",
      "64\n",
      "\n",
      "[ 9 14 28 26 25 23 21 19 15 29 10 11 12 22 27]\n",
      "18\n",
      "1\n",
      "[ 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29]\n",
      "556/556 [==============================] - 2s 4ms/step - loss: 0.7453 - accuracy: 0.8509\n",
      "***********************************************************************\n",
      "65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n = int(30)\n",
    "t = 9\n",
    "\n",
    "# *****************第一轮\n",
    "# 先选取百分之50，截取数据\n",
    "# 然后学习字典\n",
    "loss_9 = []\n",
    "\n",
    "# *****************后续\n",
    "# 先选取百分之50，截取数据\n",
    "# 学习字典Dt\n",
    "# 截取数据\n",
    "# 使用last_D，重构\n",
    "# 得到重构误差\n",
    "# K-means-fedavg\n",
    "\n",
    "model_list = fit_allmodel(model_list)\n",
    "model_list = sc_attack(model_list, t)\n",
    "min_indices, weights = select_min(model_list)\n",
    "extracted_X = X_dic(weights, min_indices, 15)\n",
    "model_list, loss, accuracy = fed_avg_1(model_list)\n",
    "D = learn_dic(extracted_X, 15)\n",
    "\n",
    "### Reconstructed_2，里面有几个参数，需要设置成\n",
    "\n",
    "for i in range(100):\n",
    "    # 先训练\n",
    "    updated_model_list = list(model_list)\n",
    "    model_list.clear()\n",
    "    updated_model_list = fit_allmodel(updated_model_list)\n",
    "    updated_model_list = sc_attack(updated_model_list, t)\n",
    "    min_indices, weights = select_min(updated_model_list)\n",
    "    extracted_X = X_dic(weights, min_indices, 15)\n",
    "    X = slicing_X(weights, 15, n) # 20是截取数据的长度\n",
    "    # 重构误差使用n-1次迭代的字典重构n次的误差\n",
    "    reconstruction_error = Reconstructed_2(D, X)\n",
    "    updated_model_list, loss, accuracy = fed_avg_2(updated_model_list, reconstruction_error)\n",
    "    D = learn_dic(extracted_X, 15)\n",
    "\n",
    "    print(\"***********************************************************************\")\n",
    "    loss_9.append(loss)\n",
    "    print(i)\n",
    "    model_list = list(updated_model_list)\n",
    "    updated_model_list.clear()\n",
    "    model_list[0].save('my_model_1_9.h5')\n",
    "scipy.io.savemat('loss_9_1.mat', mdict={'loss_9': loss_9})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aa2f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "scipy.io.savemat('loss_9_1.mat', mdict={'loss_9': loss_9,})\n",
    "    #批量保存data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e7f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list =[]\n",
    "\n",
    "for i in range(30):\n",
    "    model = set_model()\n",
    "    model_list.append(model)\n",
    "n = int(30)\n",
    "t = 6\n",
    "#*****************第一轮\n",
    "#先选取百分之50，截取数据\n",
    "#然后学习字典\n",
    "loss_6 = []\n",
    "#*****************后续\n",
    "#先选取百分之50，截取数据\n",
    "#学习字典Dt\n",
    "#截取数据\n",
    "#使用last_D，重构\n",
    "#得到重构误差\n",
    "#K-means-fedavg\n",
    "\n",
    "model_list = fit_allmodel(model_list)\n",
    "model_list = sc_attack(model_list,t)\n",
    "min_indices,weights = select_min(model_list)\n",
    "extracted_X = X_dic(weights, min_indices,15)\n",
    "model_list,loss,accuracy = fed_avg_1(model_list)\n",
    "D = learn_dic(extracted_X,15)\n",
    "###   Reconstructed_2,里面有几个参数，需要设置成\n",
    "\n",
    "for i in range (100):   \n",
    "    #先训练\n",
    "    model_list = fit_allmodel(model_list)\n",
    "    model_list = sc_attack(model_list,t)\n",
    "    min_indices,weights = select_min(model_list)\n",
    "    extracted_X = X_dic(weights, min_indices,15)\n",
    "    X = slicing_X(weights,15,n) #20是截取数据的长度\n",
    "    #重构误差 使用n-1次迭代的字典重构n次的误差\n",
    "    reconstruction_error = Reconstructed_2(D,X)\n",
    "    model_list,loss,accuracy = fed_avg_2(model_list,reconstruction_error)\n",
    "    D = learn_dic(extracted_X,15)    \n",
    "    print(\"***********************************************************************\")\n",
    "    loss_6.append(loss)\n",
    "    print(i)\n",
    "scipy.io.savemat('loss_6_1.mat', mdict={'loss_6': loss_6,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e28009",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list =[]\n",
    "\n",
    "for i in range(30):\n",
    "    model = set_model()\n",
    "    model_list.append(model)\n",
    "n = int(30)\n",
    "t = 3\n",
    "#*****************第一轮\n",
    "#先选取百分之50，截取数据\n",
    "#然后学习字典\n",
    "loss_3 = []\n",
    "#*****************后续\n",
    "#先选取百分之50，截取数据\n",
    "#学习字典Dt\n",
    "#截取数据\n",
    "#使用last_D，重构\n",
    "#得到重构误差\n",
    "#K-means-fedavg\n",
    "\n",
    "model_list = fit_allmodel(model_list)\n",
    "model_list = sc_attack(model_list,t)\n",
    "min_indices,weights = select_min(model_list)\n",
    "extracted_X = X_dic(weights, min_indices,15)\n",
    "model_list,loss,accuracy = fed_avg_1(model_list)\n",
    "D = learn_dic(extracted_X,15)\n",
    "###   Reconstructed_2,里面有几个参数，需要设置成\n",
    "\n",
    "for i in range (100):   \n",
    "    #先训练\n",
    "    model_list = fit_allmodel(model_list)\n",
    "    model_list = sc_attack(model_list,t)\n",
    "    min_indices,weights = select_min(model_list)\n",
    "    extracted_X = X_dic(weights, min_indices,15)\n",
    "    X = slicing_X(weights,15,n) #20是截取数据的长度\n",
    "    #重构误差 使用n-1次迭代的字典重构n次的误差\n",
    "    reconstruction_error = Reconstructed_2(D,X)\n",
    "    model_list,loss,accuracy = fed_avg_2(model_list,reconstruction_error)\n",
    "    D = learn_dic(extracted_X,15)    \n",
    "    print(i)\n",
    "    print(\"***********************************************************************\")\n",
    "    loss_3.append(loss)\n",
    "scipy.io.savemat('loss_3_1.mat', mdict={'loss_3': loss_3,})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08135ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef80a8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34edc30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123b0f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b351f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "94bdf5c9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16443413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d91c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb97b318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0f34e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c68f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a8ff14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f271cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a768046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
